{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/A6Qw2voEiEl08YHp4fbd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Questão ponderada: Álgebra linear na redução de dimensionalidade\n","\n","A questão ponderada começa a partir da seção \"Autovalores e autovetores da matriz de covariância\". Tudo que vem antes foi feito para fins de aprendizagem."],"metadata":{"id":"vkj-4v658PgW"}},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"BoeX_0K0MOob","executionInfo":{"status":"ok","timestamp":1714345184959,"user_tz":180,"elapsed":7,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zPw3cn6nLA3Y","executionInfo":{"status":"ok","timestamp":1714345184960,"user_tz":180,"elapsed":5,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}}},"outputs":[],"source":["vector_gradient = [30, 25, 28, 20, 32]\n","vector_productivity = [20, 18, 22, 16, 25]"]},{"cell_type":"markdown","source":["### Normalização"],"metadata":{"id":"azZe_uEtNcIY"}},{"cell_type":"code","source":["def normalize(vector):\n","  result_vector = []\n","\n","  stardart_deviation = np.std(vector)\n","  for n in vector:\n","    result_vector.append((n - np.mean(vector)) / stardart_deviation)\n","\n","  return result_vector"],"metadata":{"id":"qh79AtIRLVi6","executionInfo":{"status":"ok","timestamp":1714345184960,"user_tz":180,"elapsed":4,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["v1 = normalize(vector_gradient)\n","v1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s0GAfWwRMllc","executionInfo":{"status":"ok","timestamp":1714345185837,"user_tz":180,"elapsed":22,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}},"outputId":"11402ca3-d764-42e8-ebdf-bbed8d51ce26"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7150969419341942,\n"," -0.4767312946227961,\n"," 0.23836564731139806,\n"," -1.6685595311797865,\n"," 1.1918282365569903]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["v2 = normalize(vector_productivity)\n","v2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8bIam98Mvs3","executionInfo":{"status":"ok","timestamp":1714345185838,"user_tz":180,"elapsed":17,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}},"outputId":"cd82961c-0037-4d8b-ca7c-c25c93ef646d"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[-0.06401843996644777,\n"," -0.7042028396309277,\n"," 0.5761659596980321,\n"," -1.3443872392954075,\n"," 1.536442559194752]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Matriz de covariância"],"metadata":{"id":"Mk8ZcyX-NfUk"}},{"cell_type":"code","source":["covariance_matrix = np.cov(v1, v2)"],"metadata":{"id":"qFE90SlkOolw","executionInfo":{"status":"ok","timestamp":1714345716437,"user_tz":180,"elapsed":273,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["covariance_matrix"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DB8q6t_e9440","executionInfo":{"status":"ok","timestamp":1714345718198,"user_tz":180,"elapsed":2,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}},"outputId":"425606a9-c96b-4558-95ae-f85beb8c2ed8"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.25      , 1.12541002],\n","       [1.12541002, 1.25      ]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["# Autovalores e autovetores da matriz de covariância"],"metadata":{"id":"_bb1ffIOQla_"}},{"cell_type":"code","source":["covariance_matrix = [[4, 2], [2, 3]]"],"metadata":{"id":"JKh42HwY9o1E","executionInfo":{"status":"ok","timestamp":1714345739492,"user_tz":180,"elapsed":265,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)"],"metadata":{"id":"gRo3zpmRQoOX","executionInfo":{"status":"ok","timestamp":1714345740640,"user_tz":180,"elapsed":4,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["eigenvalues"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TmJmWvMmUD3Q","executionInfo":{"status":"ok","timestamp":1714345743364,"user_tz":180,"elapsed":254,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}},"outputId":"9b3f1852-81a7-41e3-800a-35dc752bba88"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5.56155281, 1.43844719])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["eigenvectors"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MT364IZvUEtT","executionInfo":{"status":"ok","timestamp":1714345744816,"user_tz":180,"elapsed":265,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}},"outputId":"3c5a4b7b-f4c5-43ec-fbcc-b27022f532bb"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.78820544, -0.61541221],\n","       [ 0.61541221,  0.78820544]])"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["# Realizar uma Análise de Componentes Principais\n","Agora que temos os autovetores, eles formam as direções dos componentes principais. Ordenamos os componentes principais pela magnitude dos autovalores. O primeiro componente principal é aquele associado ao maior autovalor, pois explica a maior variância."],"metadata":{"id":"AS2o54dd62HL"}},{"cell_type":"markdown","source":["# Determinar a Proporção da Variância Explicada\n","\n","A proporção da variância explicada por cada componente é dada pelo quociente entre o autovalor correspondente e a soma de todos os autovalores."],"metadata":{"id":"82dVRzIj67Xc"}},{"cell_type":"code","source":["total = sum(eigenvalues)\n","variance_ratios = [(ev / total) for ev in eigenvalues]\n","variance_ratios"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e62NyRZc7DB0","executionInfo":{"status":"ok","timestamp":1714345746990,"user_tz":180,"elapsed":255,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"}},"outputId":"94053d35-9555-42f8-9416-1ba84a14b88c"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7945075446869758, 0.20549245531302424]"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["# Redução de Dimensionalidade\n","\n","Para reduzir a dimensionalidade, mantemos apenas os componentes principais que explicam a maior parte da variância, descartando aqueles com autovalores menores. Isso é útil em grandes conjuntos de dados para reduzir o número de variáveis e ainda assim capturar a maior parte da informação."],"metadata":{"id":"ysgbSKCE7870"}}]}